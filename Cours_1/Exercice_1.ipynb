{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercice_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSEC4mEySWcZ"
      },
      "source": [
        "# Partie I\n",
        "\n",
        "Objectifs :\n",
        "- Créer un jeu de données ;\n",
        "- Mettre le texte en minuscule ;\n",
        "- Suppression de la ponctuation ;\n",
        "- Séparation en tokens ;\n",
        "- Visualisation du vocabulaire des articles classé par ordre décroissant avec un barplot ;\n",
        "- Suppression des stopwords ;\n",
        "- Visualisation du vocabulaire des articles classé par ordre décroissant avec un barplot après supression des stopwords ;\n",
        "- Création d'une version avec stemming du document ;\n",
        "- Visualisation du vocabulaire des articles classé par ordre décroissant avec un barplot après le stemming ;\n",
        "- Création d'une version avec lemmatization du document ;\n",
        "- Visualisation du vocabulaire des articles classé par ordre décroissant avec un barplot après la lemmatization ;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmmcT3k5ZrQV"
      },
      "source": [
        "## Importations des packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXPNc6P3ZuEq",
        "outputId": "97356736-9ace-4716-e643-43ffde888c26"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.text import Text\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZJ8Idw4Zx8T"
      },
      "source": [
        "## Importations des données\n",
        "\n",
        "Les données sont issue de [cette base de données](https://cs.nyu.edu/~kcho/DMQA/).\n",
        "\n",
        "Maintenant que nos outils sont chargés, nous allons charger nos données.\n",
        "\n",
        "Cliquez sur le lien ci-dessous :\n",
        "\n",
        "https://drive.google.com/drive/folders/12OmusfAUOcoLOCwEc--nfkKQ5eEozU45?usp=sharing\n",
        "\n",
        "Cliquer droit sur le dossier data et appuyer sur ajouter à mon drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzZiAVnSRB-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6d2d9b0-67d2-44d1-b331-0cd6da37f6dd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Njk5BWjZ4K4"
      },
      "source": [
        "Les données sont maintenant dans votre environnement collab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGebIlFrZoVR",
        "outputId": "4e4dc7a4-d25b-4a1c-81b1-4aa6f631827f"
      },
      "source": [
        "import os\n",
        "print(os.listdir('gdrive/MyDrive/Exercice_1/Partie_1')[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0a3ff2f0a147c158845afa44d2a012064896566b.story', '0a3fff5779a8f7cfdde5d284a429ab89fd5e85df.story', '0a0f56ebc5a0a67ed18de79d99b40a42d8058d04.story', '0a3ad75d92c5bc2eccf2763df86afe5ddeffed75.story', '0a3f2400ba4e5cdf4b3638ae6fb60fdfa12a2680.story', '0a3f567efff9f0748b2758c9e8c17dc66beade04.story', '0a05b14962b2e73bbff82086762e0e23d32b359f.story', '0a1ad82d161d90d758240407cb8c8fcebff4a212.story', '0a4ec4d37683347ca62b53982d2c5f4efb86f444.story', '0a4b2d4ea5fb0625e3e747525062f0a85345e4df.story']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrHBJQqyeTzY"
      },
      "source": [
        "## Création de la base de données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zblR3PUulPJH"
      },
      "source": [
        "## En minuscule "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnADqXpAeW5R"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICzt3a3ZeaPE"
      },
      "source": [
        "## Visualization du vocabulaire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5qb72hYhk6W"
      },
      "source": [
        "## Les stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4yKIhidisOA"
      },
      "source": [
        "## Stemming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WofRCuC7mOU_"
      },
      "source": [
        "## Lemmatization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IBUmVP2pKbu"
      },
      "source": [
        "# Partie II - Détecter le language du texte grâce au stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sqxiGxip10r"
      },
      "source": [
        "Les stopwords sont les mots les plus utilisés dans un texte grâce à eux essayé de prédire la langue du texte.\n",
        "\n",
        "Prédire pour cinq languages : \n",
        "- Français ;\n",
        "- Anglais ;\n",
        "- Espagnol ;\n",
        "- Italien ;\n",
        "- Russe.\n",
        "\n",
        "Vérifier le nombre de stopwords de chaque langue dans un texte. La langue prédit sera celle avec le plus de stopwords.\n",
        "\n",
        "Vous pourrez trouver de l'aide via ce [lien](https://www.nltk.org/book/ch02.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVR9MFaKyvhv"
      },
      "source": [
        "## Importation des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q87Gv3zj-cpm"
      },
      "source": [
        "Les données proviennent de ce [jeux de données](https://zenodo.org/record/841984#.X_Jb2ulKjBI)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNiV9Sll-CrM",
        "outputId": "93995fe8-6bea-4e8b-d5cd-2a59f434facf"
      },
      "source": [
        "x_text = pd.read_csv('gdrive/MyDrive/Exercice_1/Partie_2/x_text.csv')\n",
        "y_text = pd.read_csv('gdrive/MyDrive/Exercice_1/Partie_2/y_text.csv')\n",
        "print(x_text.shape)\n",
        "print(y_text.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2500, 1)\n",
            "(2500, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "EiKZbvHN-yvP",
        "outputId": "208f0361-79a6-4001-c25a-2af8bc9de4a8"
      },
      "source": [
        "x_text.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16 апреля 2009 года в Шатойском районе произош...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>La ciudad de San Cristóbal es sede del Hospita...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Les supporters de l'ASM Clermont Auvergne ont ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Anton (or Antonius) Maria Schyrleus (also Schy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ralph Staub est un réalisateur, producteur, sc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  16 апреля 2009 года в Шатойском районе произош...\n",
              "1  La ciudad de San Cristóbal es sede del Hospita...\n",
              "2  Les supporters de l'ASM Clermont Auvergne ont ...\n",
              "3  Anton (or Antonius) Maria Schyrleus (also Schy...\n",
              "4  Ralph Staub est un réalisateur, producteur, sc..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qu0hSDfD-1K-",
        "outputId": "22f53a2f-48fb-4282-9bfc-8b29216c30d0"
      },
      "source": [
        "lang = np.unique(y_text)\n",
        "print(lang)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['english' 'french' 'italian' 'russian' 'spanish']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}